# Person-to-Character Animation Pipeline Summary

## Overview
Created a complete pipeline that transforms a person in a video into an animated character using Gemini's Nano Banana model and Runway's Act-Two API.

## Pipeline Location
- **Main Script**: `pipelines/person_animation/main.py`
- **Supporting Files**: 
  - `pipelines/person_animation/nano_banana.py` - Gemini image generation
  - `pipelines/person_animation/runway.py` - Runway Act-Two API interface
- **Data Folder**: `/Users/amirshachar/Desktop/Amir/Projects/Personal/toontune/backend/uploads/assets/runway_experiment/`

## Pipeline Workflow
1. **Extract frame** at 0.5s from input video → `frame0.png`
2. **Extract video segment** from 0.5s to 3.55s → `runway_subvideo.mp4` (must be >3s for Runway)
3. **Generate character image** using Gemini Nano Banana → `runway_character.png`
4. **Generate character animation** using Runway Act-Two → `runway_act_two_output.mp4`
5. **Replace segment** in original video with animated character
6. **Add audio** from MP3 file if present → `final_character_video.mp4`

## Key Implementation Details

### Gemini Nano Banana Configuration
- Model: `gemini-2.5-flash-image-preview` (from env var `GEMINI_NANO_BANANA`)
- **Critical**: Must use `responseModalities: ["TEXT", "IMAGE"]` in `generationConfig`
- Response contains image in `inlineData` field (camelCase, not `inline_data`)
- Cannot use `responseMimeType: "application/json"` with image generation

### Runway Act-Two
- Uses SDK if available, falls back to REST API
- Parameters structure:
  ```python
  character={'type': 'image', 'uri': character_image_uri}
  reference={'type': 'video', 'uri': driver_video_uri}
  ratio='1280:720'
  ```
- Requires minimum $10 credits in account
- Video segment must be at least 3 seconds

### Smart Features
- **Caching**: Checks if artifacts exist before regenerating (prevents unnecessary API calls)
- **Audio Handling**: Automatically finds and uses MP3 file in same directory
- **No-audio Support**: Handles videos without audio tracks gracefully
- **Automatic Output Location**: Saves all outputs in same folder as input video

## Current Status
✅ **Fully Working Pipeline** with:
- Gemini image generation working
- Runway Act-Two API working (with credits)
- Audio integration from MP3 files
- Smart caching to avoid redundant API calls
- All outputs saved to input video's directory

## Test Command
```bash
python pipelines/person_animation/main.py /Users/amirshachar/Desktop/Amir/Projects/Personal/toontune/backend/uploads/assets/runway_experiment/runway_demo_input.mp4 --character "friendly meerkat"
```

## Artifacts Generated
All saved in `/uploads/assets/runway_experiment/`:
- `frame0.png` - Frame at 0.5s
- `runway_character.png` - Gemini-generated character
- `runway_subvideo.mp4` - 3.05s driver video
- `runway_act_two_output.mp4` - Runway animation
- `final_character_video.mp4` - Final video with audio

## Environment Variables Required
- `GEMINI_API_KEY` - For Gemini API
- `GEMINI_NANO_BANANA` - Model name (default: `gemini-2.5-flash-image-preview`)
- `RUNWAYML_API_SECRET` or `RUNWAY_API_KEY` - For Runway API

## Known Issues/Limitations
- Runway requires minimum $10 credits
- Video segment must be >3 seconds for Act-Two
- Gemini imagen sometimes returns placeholder (API still in preview)