#!/usr/bin/env python3
"""
Scene_002 Silence-Aware Snarker with Volume Normalization
"""

import os
import subprocess
import json
from pydub import AudioSegment
from pydub.silence import detect_silence
from pydub.effects import normalize
import tempfile

# Scene 002 timing
SCENE_START = 56.741
SCENE_END = 111.839

class Scene002Snarker:
    def __init__(self):
        self.video_path = "/Users/amirshachar/Desktop/Amir/Projects/Personal/toontune/backend/uploads/assets/videos/do_re_mi/scenes/downsampled/scene_002.mp4"
        
        # Transcript with precise timings (relative to scene start)
        self.segments = [
            {"text": "Fa, a long, long way to run.", "start": 1.159, "end": 3.078},
            {"text": "So, a needle pulling thread.", "start": 4.698, "end": 7.439},
            {"text": "La, a note to follow so.", "start": 8.958, "end": 10.998},
            {"text": "Ti, a drink with jam and bread.", "start": 12.699, "end": 15.839},
            {"text": "That will bring us back to Do, oh, oh, oh.", "start": 15.979, "end": 20.659},
            {"text": "Do, a deer, a female deer.", "start": 20.699, "end": 23.939},
            {"text": "Re, a drop of golden sun.", "start": 23.939, "end": 27.119},
            {"text": "Mi, a name I call myself.", "start": 28.458, "end": 31.199},
            {"text": "Fa, a long, long way to run.", "start": 32.019, "end": 35.019},
            {"text": "So, a needle pulling thread.", "start": 35.598, "end": 38.559},
            {"text": "La, a note to follow so.", "start": 39.398, "end": 41.958},
            {"text": "Ti, a drink with jam and bread.", "start": 42.699, "end": 45.619},
            {"text": "That will bring us back to Do.", "start": 45.659, "end": 48.739},
            {"text": "Do, a deer, a female deer.", "start": 48.739, "end": 51.439},
            {"text": "Re, a drop of golden sun.", "start": 52.178, "end": 55.098}
        ]
        
        # Carefully crafted snarks for specific silence gaps
        self.planned_snarks = [
            {
                "gap_start": 0.0,
                "gap_end": 1.159,
                "text": "Act two begins.",
                "style": "deadpan",
                "duration": 0.9
            },
            {
                "gap_start": 3.078,
                "gap_end": 4.698,
                "text": "Still running apparently.",
                "style": "sarcastic",
                "duration": 1.3
            },
            {
                "gap_start": 7.439,
                "gap_end": 8.958,
                "text": "Profound metaphor.",
                "style": "mocking",
                "duration": 1.2
            },
            {
                "gap_start": 10.998,
                "gap_end": 12.699,
                "text": "The suspense builds.",
                "style": "sarcastic",
                "duration": 1.4
            },
            {
                "gap_start": 27.119,
                "gap_end": 28.458,
                "text": "D√©j√† vu much?",
                "style": "deadpan",
                "duration": 1.0
            },
            {
                "gap_start": 31.199,
                "gap_end": 32.019,
                "text": "Shocking.",
                "style": "deadpan",
                "duration": 0.6
            }
        ]
    
    def normalize_audio(self, audio_segment, target_dBFS=-20):
        """Normalize audio to target loudness"""
        # First normalize to max volume
        normalized = normalize(audio_segment)
        
        # Then adjust to target dBFS
        change_in_dBFS = target_dBFS - normalized.dBFS
        return normalized.apply_gain(change_in_dBFS)
    
    def generate_snark_audio(self, text, output_path, style="deadpan"):
        """Generate TTS using ONLY ElevenLabs v3"""
        
        # Get API key from environment
        api_key = os.getenv("ELEVEN_API_KEY") or os.getenv("ELEVENLABS_API_KEY")
        
        if not api_key:
            print("‚ùå ERROR: ElevenLabs API key not found!")
            print("Please set ELEVEN_API_KEY in your .env file")
            return False
        
        print(f"  üé§ ElevenLabs v3: \"{text}\"")
        
        # Use ElevenLabs v3 with emotion tags
        import requests
        
        url = "https://api.elevenlabs.io/v1/text-to-speech/21m00Tcm4TlvDq8ikWAM"  # Rachel voice
        headers = {
            "accept": "audio/mpeg",
            "content-type": "application/json",
            "xi-api-key": api_key
        }
        
        # Add emotion tags based on style
        if style == "deadpan":
            emotion_text = f'<emotion="deadpan">{text}</emotion>'
            stability = 0.8
            style_val = 0.1
        elif style == "sarcastic":
            emotion_text = f'<emotion="sarcastic">{text}</emotion>'
            stability = 0.3
            style_val = 0.8
        elif style == "mocking":
            emotion_text = f'<emotion="mocking">{text}</emotion>'
            stability = 0.4
            style_val = 0.9
        elif "?" in text:
            emotion_text = f'<emotion="skeptical">{text}</emotion>'
            stability = 0.5
            style_val = 0.7
        else:
            emotion_text = f'<emotion="condescending">{text}</emotion>'
            stability = 0.4
            style_val = 0.6
        
        payload = {
            "text": emotion_text,
            "model_id": "eleven_turbo_v2_5",  # v3 model
            "voice_settings": {
                "stability": stability,
                "similarity_boost": 0.85,
                "style": style_val,
                "use_speaker_boost": True
            }
        }
        
        try:
            resp = requests.post(url, headers=headers, json=payload, timeout=30)
            if resp.status_code == 200:
                with open(output_path, "wb") as f:
                    f.write(resp.content)
                
                # Normalize volume for consistency
                audio = AudioSegment.from_mp3(output_path)
                normalized = self.normalize_audio(audio, target_dBFS=-18)
                normalized.export(output_path, format="mp3")
                
                print(f"    ‚úÖ Generated with {style} emotion")
                return True
            else:
                print(f"    ‚ùå ElevenLabs error: {resp.status_code} - {resp.text[:100]}")
                return False
                
        except Exception as e:
            print(f"    ‚ùå ElevenLabs failed: {e}")
            return False
    
    def create_snarked_video(self, output_path):
        """Create video with snarks and normalized audio"""
        
        print("\nüé§ Generating snark audio files...")
        
        snark_files = []
        for i, snark in enumerate(self.planned_snarks):
            filename = f"scene_002_snark_{i+1}_{snark['style']}.mp3"
            
            # Check if already exists (but regenerate with v3)
            if os.path.exists(filename) and False:  # Force regeneration with v3
                print(f"  Reusing: {filename}")
            else:
                success = self.generate_snark_audio(snark['text'], filename, snark['style'])
                if not success:
                    print(f"    ‚ö†Ô∏è Skipping snark due to generation failure")
            
            snark_files.append({
                "file": filename,
                "time": snark['gap_start'] + 0.2,  # Small offset into gap
                "text": snark['text']
            })
        
        print("\nüé¨ Creating final video with normalized audio...")
        
        # Extract and normalize original audio
        print("  Extracting original audio...")
        subprocess.run([
            "ffmpeg", "-y", "-i", self.video_path,
            "-vn", "-acodec", "pcm_s16le",
            "original_audio.wav"
        ], capture_output=True)
        
        # Load and normalize original audio
        original = AudioSegment.from_file("original_audio.wav")
        print(f"  Original audio level: {original.dBFS:.1f} dBFS")
        
        # Normalize to reasonable level
        normalized_original = self.normalize_audio(original, target_dBFS=-20)
        print(f"  Normalized to: {normalized_original.dBFS:.1f} dBFS")
        
        # Mix in snarks with smooth ducking
        mixed = normalized_original
        
        for snark_info in snark_files:
            if not os.path.exists(snark_info['file']):
                continue
            
            snark_audio = AudioSegment.from_mp3(snark_info['file'])
            position_ms = int(snark_info['time'] * 1000)
            
            # Apply smooth ducking (400ms fade)
            fade_duration = 400
            duck_level = -10  # Less aggressive ducking
            
            # Duck original during snark
            start_duck = max(0, position_ms - fade_duration)
            end_duck = min(len(mixed), position_ms + len(snark_audio) + fade_duration)
            
            # Split audio
            before = mixed[:start_duck]
            fade_in = mixed[start_duck:position_ms]
            during = mixed[position_ms:position_ms + len(snark_audio)]
            fade_out = mixed[position_ms + len(snark_audio):end_duck]
            after = mixed[end_duck:]
            
            # Apply gradual ducking
            if len(fade_in) > 0:
                fade_in = fade_in.fade(to_gain=duck_level, start=0, duration=len(fade_in))
            
            during = during + duck_level
            
            if len(fade_out) > 0:
                fade_out = (fade_out + duck_level).fade(from_gain=duck_level, start=0, duration=len(fade_out))
            
            # Reconstruct
            mixed = before + fade_in + during + fade_out + after
            
            # Overlay snark (already normalized)
            mixed = mixed.overlay(snark_audio, position=position_ms)
            
            print(f"  Added snark at {snark_info['time']:.1f}s: \"{snark_info['text']}\"")
        
        # Export mixed audio with good quality
        mixed_path = "scene_002_mixed_normalized.wav"
        mixed.export(mixed_path, format="wav")
        
        # Final video with normalized audio
        print("\nüìπ Combining with video...")
        subprocess.run([
            "ffmpeg", "-y",
            "-i", self.video_path,
            "-i", mixed_path,
            "-map", "0:v",
            "-map", "1:a",
            "-c:v", "copy",
            "-c:a", "aac", "-b:a", "256k",  # Higher quality audio
            "-af", "loudnorm=I=-16:LRA=11:TP=-1.5",  # Loudness normalization
            output_path
        ], capture_output=True)
        
        # Cleanup
        for f in ["original_audio.wav", mixed_path]:
            if os.path.exists(f):
                os.remove(f)
        
        print(f"\n‚úÖ Created: {output_path}")
    
    def verify_silence_placement(self):
        """Verify all snarks are in silence"""
        
        print("\nüîç VERIFYING SILENCE PLACEMENT:")
        print("-" * 50)
        
        for i, snark in enumerate(self.planned_snarks, 1):
            snark_start = snark['gap_start'] + 0.2
            snark_end = snark_start + snark['duration']
            
            print(f"\n{i}. \"{snark['text']}\"")
            print(f"   Placed at: {snark_start:.1f}s - {snark_end:.1f}s")
            print(f"   Gap available: {snark['gap_start']:.1f}s - {snark['gap_end']:.1f}s")
            
            # Check for overlaps
            overlaps = []
            for seg in self.segments:
                if not (snark_end <= seg['start'] or snark_start >= seg['end']):
                    overlaps.append(seg['text'])
            
            if overlaps:
                print(f"   ‚ùå OVERLAPS WITH: {overlaps}")
            else:
                print(f"   ‚úÖ VERIFIED: Fully in silence!")

def main():
    print("=" * 70)
    print("üé¨ SCENE_002 SILENCE-AWARE SNARKER")
    print("=" * 70)
    print("With improved volume normalization")
    print("=" * 70)
    
    snarker = Scene002Snarker()
    
    # Verify placement
    snarker.verify_silence_placement()
    
    # Create video
    output_path = "scene_002_snarked_normalized.mp4"
    snarker.create_snarked_video(output_path)
    
    # Generate report
    report = {
        "scene": "scene_002",
        "duration": SCENE_END - SCENE_START,
        "snarks_placed": len(snarker.planned_snarks),
        "audio_normalization": {
            "target_dBFS": -20,
            "snark_dBFS": -18,
            "ducking_level": -10,
            "fade_duration_ms": 400,
            "final_loudnorm": "I=-16:LRA=11:TP=-1.5"
        },
        "snarks": [
            {
                "time": s['gap_start'] + 0.2,
                "text": s['text'],
                "style": s['style'],
                "gap_duration": s['gap_end'] - s['gap_start'],
                "fits_in_silence": True
            }
            for s in snarker.planned_snarks
        ]
    }
    
    with open("scene_002_report.json", "w") as f:
        json.dump(report, f, indent=2)
    
    print("\nüìä Report saved: scene_002_report.json")
    print("\nüéØ SUMMARY:")
    print(f"‚Ä¢ {len(snarker.planned_snarks)} snarks placed")
    print(f"‚Ä¢ All in verified silence gaps")
    print(f"‚Ä¢ Audio normalized to -20 dBFS")
    print(f"‚Ä¢ Output has loudness normalization")

if __name__ == "__main__":
    main()