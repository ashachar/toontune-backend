<?xml version="1.0" ?>
<context issue="the same issue occurs, the resolution of the letters in the final vidoe is low, there's a &quot;staircase&quot; effect in letters like A, see the image for example: [Image #1]

Your task is to create a concise, self-contained markdown fenced by single code widget, with instructions how the agent that reads your instructions should proceed. include thorough code examples and references and also high-level instructions. assume he's not so smart.">
  <files count="3">
    <file path="utils/animations/text_3d_motion.py">#!/usr/bin/env python3
&amp;quot;&amp;quot;&amp;quot;
3D text motion animation with shrinking and moving behind subject.
Extracted from Text3DMotionDissolve to be a standalone, reusable animation.

Fixes applied:
- Correct centering by front-face center (not canvas top-left).
- Consistent anchor computation with depth margins.
- [POS_HANDOFF] debug logs to verify handoff to dissolve.
&amp;quot;&amp;quot;&amp;quot;

import cv2
import numpy as np
from PIL import Image, ImageDraw, ImageFont
from typing import Optional, Tuple, Dict
from dataclasses import dataclass


@dataclass
class MotionState:
    &amp;quot;&amp;quot;&amp;quot;State captured at the end of motion animation for handoff to next animation.&amp;quot;&amp;quot;&amp;quot;
    scale: float
    position: Tuple[int, int]           # Top-left position used during final composite (debug)
    text_size: Tuple[int, int]          # Rendered sprite size (debug)
    center_position: Tuple[int, int]    # Intended front-face center (what dissolve should use)
    is_behind: bool                      # Whether text is behind subject at end of motion


class Text3DMotion:
    &amp;quot;&amp;quot;&amp;quot;
    3D text animation that shrinks and moves behind a subject.

    This class handles:
    - 3D text rendering with depth layers
    - Smooth shrinking from large to small
    - Movement from start position to end position (interpreted as FRONT-FACE CENTER)
    - Occlusion when passing behind subject
    - Dynamic mask recalculation for moving subjects
    &amp;quot;&amp;quot;&amp;quot;

    def __init__(
        self,
        duration: float = 1.0,
        fps: int = 30,
        resolution: Tuple[int, int] = (1920, 1080),
        text: str = &amp;quot;HELLO&amp;quot;,
        segment_mask: Optional[np.ndarray] = None,
        font_size: int = 120,
        text_color: Tuple[int, int, int] = (255, 220, 0),
        depth_color: Tuple[int, int, int] = (200, 170, 0),
        depth_layers: int = 8,
        depth_offset: int = 3,
        start_scale: float = 2.0,
        end_scale: float = 1.0,
        final_scale: float = 0.9,
        start_position: Optional[Tuple[int, int]] = None,  # FRONT-FACE CENTER
        end_position: Optional[Tuple[int, int]] = None,    # FRONT-FACE CENTER
        shrink_duration: float = 0.8,
        settle_duration: float = 0.2,
        final_alpha: float = 0.3,  # Final opacity when behind subject (0.0-1.0)
        shadow_offset: int = 5,
        outline_width: int = 2,
        perspective_angle: float = 0,
        supersample_factor: int = 2,
        glow_effect: bool = True,
        debug: bool = False,
    ):
        self.duration = duration
        self.fps = fps
        self.total_frames = int(duration * fps)
        self.resolution = resolution
        self.text = text
        self.segment_mask = segment_mask
        self.font_size = font_size
        self.text_color = text_color
        self.depth_color = depth_color
        self.depth_layers = depth_layers
        self.depth_offset = depth_offset
        self.start_scale = start_scale
        self.end_scale = end_scale
        self.final_scale = final_scale

        # Positions are interpreted as FRONT-FACE CENTER of the text (not top-left).
        default_center = (resolution[0] // 2, resolution[1] // 2)
        self.start_position = start_position or default_center
        self.end_position = end_position or default_center

        self.shrink_duration = shrink_duration
        self.settle_duration = settle_duration
        self.final_alpha = final_alpha
        self.shadow_offset = shadow_offset
        self.outline_width = outline_width
        self.perspective_angle = perspective_angle
        self.supersample_factor = supersample_factor
        self.glow_effect = glow_effect
        self.debug = debug

        # Cache for dynamic masks
        self._frame_mask_cache: Dict[int, np.ndarray] = {}

        # Final state for handoff
        self._final_state: Optional[MotionState] = None

    def _log(self, message: str):
        &amp;quot;&amp;quot;&amp;quot;Debug logging (required format).&amp;quot;&amp;quot;&amp;quot;
        if self.debug:
            print(f&amp;quot;[POS_HANDOFF] {message}&amp;quot;)

    def _get_font(self, size: int) -&amp;gt; ImageFont.FreeTypeFont:
        &amp;quot;&amp;quot;&amp;quot;Get font at specified size.&amp;quot;&amp;quot;&amp;quot;
        try:
            return ImageFont.truetype(&amp;quot;/System/Library/Fonts/Helvetica.ttc&amp;quot;, size)
        except:
            return ImageFont.load_default()

    def _smoothstep(self, t: float) -&amp;gt; float:
        &amp;quot;&amp;quot;&amp;quot;Smooth interpolation function.&amp;quot;&amp;quot;&amp;quot;
        t = max(0, min(1, t))
        return t * t * (3 - 2 * t)

    def _render_3d_text(
        self,
        text: str,
        scale: float,
        alpha: float,
        depth_scale: float
    ) -&amp;gt; Tuple[Image.Image, Tuple[int, int], Tuple[int, int]]:
        &amp;quot;&amp;quot;&amp;quot;
        Render 3D text with depth layers.

        Returns:
            canvas (PIL.Image)
            anchor (ax, ay): FRONT-FACE top-left *inside* canvas coordinates (post downsample)
            front_size (fw, fh): FRONT-FACE bbox size (post downsample)
        &amp;quot;&amp;quot;&amp;quot;
        from PIL import ImageFilter
        
        # Work at supersampled resolution for quality
        font_px = int(self.font_size * scale * self.supersample_factor)
        font = self._get_font(font_px)

        # FRONT-FACE bbox (no depth)
        tmp = Image.new(&amp;quot;RGBA&amp;quot;, (4, 4), (0, 0, 0, 0))
        d = ImageDraw.Draw(tmp)
        bbox = d.textbbox((0, 0), text, font=font)  # (l, t, r, b)
        bbox_w = bbox[2] - bbox[0]
        bbox_h = bbox[3] - bbox[1]

        # Margin to accommodate depth layers on both sides (symmetric canvas)
        margin = int(self.depth_offset * self.depth_layers * self.supersample_factor)

        width = bbox_w + 2 * margin
        height = bbox_h + 2 * margin

        canvas = Image.new(&amp;quot;RGBA&amp;quot;, (width, height), (0, 0, 0, 0))
        draw = ImageDraw.Draw(canvas)

        # Render depth layers back-to-front
        for i in range(self.depth_layers - 1, -1, -1):
            depth_alpha = int(alpha * 255 * (0.3 + 0.7 * (1 - i / self.depth_layers)))
            offset = int(i * self.depth_offset * depth_scale * self.supersample_factor)
            if i == 0:
                color = (*self.text_color, depth_alpha)
            else:
                factor = 0.7 - (i / self.depth_layers) * 0.4
                color = tuple(int(c * factor) for c in self.depth_color) + (depth_alpha,)

            # Draw with symmetric margin + per-layer offset (only +x,+y)
            x = -bbox[0] + margin + offset
            y = -bbox[1] + margin + offset
            
            # Add stroke for front layer to improve antialiasing
            if i == 0 and self.supersample_factor &amp;gt;= 4:
                stroke_width = max(1, self.supersample_factor // 8)
                draw.text((x, y), text, font=font, fill=color, stroke_width=stroke_width, stroke_fill=color)
            else:
                draw.text((x, y), text, font=font, fill=color)

        # Apply Gaussian blur for antialiasing before downsampling
        if self.supersample_factor &amp;gt;= 4:
            blur_radius = self.supersample_factor / 5.0
            canvas = canvas.filter(ImageFilter.GaussianBlur(radius=blur_radius))

        # Progressive downsampling for better quality
        if self.supersample_factor &amp;gt;= 8:
            # Two-step downsampling for very high supersample factors
            intermediate_size = (width // (self.supersample_factor // 2), height // (self.supersample_factor // 2))
            canvas = canvas.resize(intermediate_size, Image.Resampling.LANCZOS)
            
            new_size = (intermediate_size[0] // 2, intermediate_size[1] // 2)
            canvas = canvas.resize(new_size, Image.Resampling.LANCZOS)
            # Convert supersampled coordinates to final coordinates
            ax = int(round((-bbox[0] + margin) / self.supersample_factor))
            ay = int(round((-bbox[1] + margin) / self.supersample_factor))
            fw = int(round(bbox_w / self.supersample_factor))
            fh = int(round(bbox_h / self.supersample_factor))
        elif self.supersample_factor &amp;gt; 1:
            new_size = (width // self.supersample_factor, height // self.supersample_factor)
            canvas = canvas.resize(new_size, Image.Resampling.LANCZOS)
            # Convert supersampled coordinates to final coordinates
            ax = int(round((-bbox[0] + margin) / self.supersample_factor))
            ay = int(round((-bbox[1] + margin) / self.supersample_factor))
            fw = int(round(bbox_w / self.supersample_factor))
            fh = int(round(bbox_h / self.supersample_factor))
        else:
            ax = -bbox[0] + margin
            ay = -bbox[1] + margin
            fw = bbox_w
            fh = bbox_h

        return canvas, (ax, ay), (fw, fh)

    def generate_frame(self, frame_number: int, background: np.ndarray) -&amp;gt; np.ndarray:
        &amp;quot;&amp;quot;&amp;quot;Generate a single frame of the motion animation.&amp;quot;&amp;quot;&amp;quot;
        frame = background.copy()

        # Ensure RGBA
        if frame.shape[2] == 3:
            frame = cv2.cvtColor(frame, cv2.COLOR_RGB2RGBA)

        # Progress
        t_global = frame_number / max(self.total_frames - 1, 1)
        smooth_t_global = self._smoothstep(t_global)

        # Scale phases
        shrink_progress = self.shrink_duration / self.duration
        if smooth_t_global &amp;lt;= shrink_progress:
            local_t = smooth_t_global / shrink_progress
            scale = self.start_scale - local_t * (self.start_scale - self.end_scale)
            depth_scale = 1.0
            is_behind = local_t &amp;gt; 0.5
            # Fade from full opacity to final_alpha during shrink
            base_alpha = 1.0 if local_t &amp;lt;= 0.5 else max(self.final_alpha, 1.0 - (local_t - 0.5) * (2.0 * (1.0 - self.final_alpha)))
        else:
            # Settle phase - maintain final_alpha
            local_t = (smooth_t_global - shrink_progress) / (1.0 - shrink_progress)
            scale = self.end_scale - local_t * (self.end_scale - self.final_scale)
            depth_scale = 1.0
            is_behind = True
            base_alpha = self.final_alpha

        # Render text (get front-face anchor + size)
        text_pil, (anchor_x, anchor_y), (front_w, front_h) = self._render_3d_text(
            self.text, scale, base_alpha, depth_scale
        )

        # Interpolate FRONT-FACE CENTER from start to end
        cx = self.start_position[0] + smooth_t_global * (self.end_position[0] - self.start_position[0])
        cy = self.start_position[1] + smooth_t_global * (self.end_position[1] - self.start_position[1])

        # Place such that FRONT-FACE CENTER == (cx, cy)
        pos_x = int(round(cx - (anchor_x + front_w / 2.0)))
        pos_y = int(round(cy - (anchor_y + front_h / 2.0)))

        # Store final state for handoff (last frame)
        if frame_number == self.total_frames - 1:
            self._final_state = MotionState(
                scale=scale,
                position=(pos_x, pos_y),
                text_size=(text_pil.width, text_pil.height),
                center_position=(int(round(cx)), int(round(cy))),
                is_behind=is_behind,
            )
            self._log(
                f&amp;quot;Motion final snapshot -&amp;gt; center=({cx:.1f},{cy:.1f}), &amp;quot;
                f&amp;quot;front_size=({front_w},{front_h}), anchor=({anchor_x},{anchor_y}), &amp;quot;
                f&amp;quot;paste_topleft=({pos_x},{pos_y}), scale={scale:.3f}, is_behind={is_behind}&amp;quot;
            )

        # Composite onto frame
        text_np = np.array(text_pil)
        tw, th = text_pil.size

        y1 = max(0, pos_y)
        y2 = min(frame.shape[0], pos_y + th)
        x1 = max(0, pos_x)
        x2 = min(frame.shape[1], pos_x + tw)

        ty1 = max(0, -pos_y)
        ty2 = ty1 + (y2 - y1)
        tx1 = max(0, -pos_x)
        tx2 = tx1 + (x2 - x1)

        # Build text layer
        text_layer = np.zeros_like(frame)
        text_layer[y1:y2, x1:x2] = text_np[ty1:ty2, tx1:tx2]

        # Apply masking when behind
        if is_behind and self.segment_mask is not None:
            # Use dynamic mask if available
            if frame_number not in self._frame_mask_cache:
                from utils.segmentation.segment_extractor import extract_foreground_mask
                current_rgb = background[:, :, :3] if background.shape[2] == 4 else background
                current_mask = extract_foreground_mask(current_rgb)

                if current_mask.shape[:2] != (self.resolution[1], self.resolution[0]):
                    current_mask = cv2.resize(current_mask, self.resolution, interpolation=cv2.INTER_LINEAR)

                current_mask = cv2.GaussianBlur(current_mask, (3, 3), 0)
                kernel = np.ones((3, 3), np.uint8)
                current_mask = cv2.dilate(current_mask, kernel, iterations=1)
                current_mask = (current_mask &amp;gt; 128).astype(np.uint8) * 255

                self._frame_mask_cache[frame_number] = current_mask
            else:
                current_mask = self._frame_mask_cache[frame_number]

            # Apply mask
            mask_region = current_mask[y1:y2, x1:x2]
            text_alpha = text_layer[y1:y2, x1:x2, 3].astype(np.float32)
            mask_factor = mask_region.astype(np.float32) / 255.0
            text_alpha *= (1.0 - mask_factor)
            text_layer[y1:y2, x1:x2, 3] = text_alpha.astype(np.uint8)

        # Composite
        frame_pil = Image.fromarray(frame)
        text_pil_img = Image.fromarray(text_layer)
        out = Image.alpha_composite(frame_pil, text_pil_img)
        result = np.array(out)

        return result[:, :, :3] if result.shape[2] == 4 else result

    def get_final_state(self) -&amp;gt; Optional[MotionState]:
        &amp;quot;&amp;quot;&amp;quot;Get the final state for handoff to next animation.&amp;quot;&amp;quot;&amp;quot;
        return self._final_state</file>
    <file path="utils/animations/letter_3d_dissolve.py">#!/usr/bin/env python3
&amp;quot;&amp;quot;&amp;quot;
3D letter dissolve animation where each letter dissolves individually.

FRAME-ACCURATE FIXES:
- Per-letter schedule computed in integer frames (start/end/fade_end).
- Guaranteed minimum fade frames (prevents skipped fades at low FPS).
- 1-frame &amp;quot;safety hold&amp;quot; at dissolve start so alpha begins EXACTLY at stable_alpha.
- Optional overlap guard: previous letter&amp;apos;s fade extends at least until next letter&amp;apos;s start.

DEBUG:
- [JUMP_CUT] logs print the full schedule and per-frame transitions.
- [POS_HANDOFF] logs from motion remain supported.

Original authorship retained; this refactor targets the jump-cut described in the issue.
&amp;quot;&amp;quot;&amp;quot;

import cv2
import numpy as np
from PIL import Image, ImageDraw, ImageFont
from typing import Optional, Tuple, List, Dict
import random
from dataclasses import dataclass

# -----------------------------
# Data structures
# -----------------------------

@dataclass
class LetterSprite:
    &amp;quot;&amp;quot;&amp;quot;Individual letter sprite with its 3D rendering and position.&amp;quot;&amp;quot;&amp;quot;
    char: str
    sprite_3d: Optional[Image.Image]
    position: Tuple[int, int]   # paste top-left
    width: int
    height: int
    anchor: Tuple[int, int]     # FRONT-FACE top-left inside sprite


@dataclass
class _LetterTiming:
    &amp;quot;&amp;quot;&amp;quot;Frame-accurate per-letter schedule.&amp;quot;&amp;quot;&amp;quot;
    start: int           # first frame letter is DEFINITELY drawn at stable_alpha
    hold_end: int        # last frame of the &amp;quot;safety hold&amp;quot; at stable_alpha (&amp;gt;= start)
    end: int             # last frame of the dissolve window (after hold)
    fade_end: int        # last frame of the fade-out tail
    order_index: int     # 0..N-1 sequential in dissolve_order


class Letter3DDissolve:
    &amp;quot;&amp;quot;&amp;quot;
    3D letter-by-letter dissolve animation with frame-accurate timing.

    Key parameters:
    - duration: total dissolve clip length (seconds)
    - dissolve_duration: time a letter spends in the dissolve window (seconds)
    - dissolve_stagger: delay between starts (seconds)
    - post_fade_seconds: additional fade after dissolve (seconds) -&amp;gt; converted to frames (min 2)
    - pre_dissolve_hold_frames: safety frames at stable_alpha before letter starts to change
    &amp;quot;&amp;quot;&amp;quot;

    def __init__(
        self,
        duration: float = 1.5,
        fps: int = 30,
        resolution: Tuple[int, int] = (1920, 1080),
        text: str = &amp;quot;HELLO&amp;quot;,
        font_size: int = 120,
        text_color: Tuple[int, int, int] = (255, 220, 0),
        depth_color: Tuple[int, int, int] = (200, 170, 0),
        depth_layers: int = 8,
        depth_offset: int = 3,
        initial_scale: float = 0.9,                   # handoff scale
        initial_position: Optional[Tuple[int, int]] = None,  # FRONT-FACE CENTER
        stable_duration: float = 0.2,                 # pre-letter dissolve lead-in (sec)
        stable_alpha: float = 0.3,                    # opacity when not dissolving (0..1)
        dissolve_duration: float = 0.8,               # per-letter dissolve (sec)
        dissolve_stagger: float = 0.1,                # delay between letter starts (sec)
        float_distance: float = 50,
        max_dissolve_scale: float = 1.3,
        randomize_order: bool = False,
        segment_mask: Optional[np.ndarray] = None,
        is_behind: bool = False,
        shadow_offset: int = 5,
        outline_width: int = 2,
        supersample_factor: int = 2,
        # --- New robustness knobs ---
        post_fade_seconds: float = 0.10,              # tail after dissolve (sec); min 2 frames
        pre_dissolve_hold_frames: int = 1,            # hold N frames at stable_alpha at start
        ensure_no_gap: bool = True,                   # extend previous fade to next start
        debug: bool = False,
    ):
        self.duration = duration
        self.fps = fps
        self.total_frames = int(round(duration * fps))
        self.resolution = resolution
        self.text = text
        self.font_size = font_size
        self.text_color = text_color
        self.depth_color = depth_color
        self.depth_layers = depth_layers
        self.depth_offset = depth_offset
        self.initial_scale = initial_scale
        self.initial_position = initial_position or (resolution[0] // 2, resolution[1] // 2)
        self.stable_duration = stable_duration
        self.stable_alpha = max(0.0, min(1.0, stable_alpha))
        self.dissolve_duration = dissolve_duration
        self.dissolve_stagger = dissolve_stagger
        self.float_distance = float_distance
        self.max_dissolve_scale = max(1.0, max_dissolve_scale)
        self.randomize_order = randomize_order
        self.segment_mask = segment_mask
        self.is_behind = is_behind
        self.shadow_offset = shadow_offset
        self.outline_width = outline_width
        self.supersample_factor = supersample_factor
        self.post_fade_seconds = max(0.0, post_fade_seconds)
        self.pre_dissolve_hold_frames = max(0, int(pre_dissolve_hold_frames))
        self.ensure_no_gap = ensure_no_gap
        self.debug = debug

        # Runtime
        self.letter_sprites: List[LetterSprite] = []
        self.dissolve_order: List[int] = []
        self.letter_kill_masks: Dict[int, np.ndarray] = {}
        self._frame_mask_cache: Dict[int, np.ndarray] = {}
        self._timeline: Dict[int, _LetterTiming] = {}
        self._entered_dissolve_logged: Dict[int, bool] = {}
        self._hold_logged: Dict[int, bool] = {}

        # Build sprites and schedule
        self._prepare_letter_sprites()
        self._init_dissolve_order()
        self._build_frame_timeline()

    # -----------------------------
    # Utilities / logging
    # -----------------------------
    def _log_pos(self, message: str):
        if self.debug:
            print(f&amp;quot;[POS_HANDOFF] {message}&amp;quot;)

    def _log_jump(self, message: str):
        if self.debug:
            print(f&amp;quot;[JUMP_CUT] {message}&amp;quot;)

    def _get_font(self, size: int) -&amp;gt; ImageFont.FreeTypeFont:
        try:
            return ImageFont.truetype(&amp;quot;/System/Library/Fonts/Helvetica.ttc&amp;quot;, size)
        except Exception:
            return ImageFont.load_default()

    @staticmethod
    def _smoothstep(t: float) -&amp;gt; float:
        t = max(0.0, min(1.0, t))
        return t * t * (3 - 2 * t)

    # -----------------------------
    # Rendering helpers
    # -----------------------------
    def _render_3d_letter(
        self, letter: str, scale: float, alpha: float, depth_scale: float
    ) -&amp;gt; Tuple[Image.Image, Tuple[int, int]]:
        from PIL import ImageFilter
        
        font_px = int(self.font_size * scale * self.supersample_factor)
        font = self._get_font(font_px)

        tmp = Image.new(&amp;quot;RGBA&amp;quot;, (4, 4), (0, 0, 0, 0))
        d = ImageDraw.Draw(tmp)
        bbox = d.textbbox((0, 0), letter, font=font)
        bbox_w = bbox[2] - bbox[0]
        bbox_h = bbox[3] - bbox[1]

        margin = int(self.depth_offset * self.depth_layers * self.supersample_factor)
        width = bbox_w + 2 * margin
        height = bbox_h + 2 * margin

        canvas = Image.new(&amp;quot;RGBA&amp;quot;, (width, height), (0, 0, 0, 0))
        draw = ImageDraw.Draw(canvas)

        for i in range(self.depth_layers - 1, -1, -1):
            depth_alpha = int(alpha * 255 * (0.3 + 0.7 * (1 - i / self.depth_layers)))
            offset = int(i * self.depth_offset * depth_scale * self.supersample_factor)

            if i == 0:
                color = (*self.text_color, depth_alpha)
            else:
                factor = 0.7 - (i / self.depth_layers) * 0.4
                color = tuple(int(c * factor) for c in self.depth_color) + (depth_alpha,)

            x = -bbox[0] + margin + offset
            y = -bbox[1] + margin + offset
            
            # Add stroke for front layer to improve antialiasing
            if i == 0 and self.supersample_factor &amp;gt;= 4:
                stroke_width = max(1, self.supersample_factor // 8)
                draw.text((x, y), letter, font=font, fill=color, stroke_width=stroke_width, stroke_fill=color)
            else:
                draw.text((x, y), letter, font=font, fill=color)

        # Apply Gaussian blur for antialiasing before downsampling
        if self.supersample_factor &amp;gt;= 4:
            blur_radius = self.supersample_factor / 5.0
            canvas = canvas.filter(ImageFilter.GaussianBlur(radius=blur_radius))

        # Progressive downsampling for better quality
        if self.supersample_factor &amp;gt;= 8:
            # Two-step downsampling for very high supersample factors
            intermediate_size = (width // (self.supersample_factor // 2), height // (self.supersample_factor // 2))
            canvas = canvas.resize(intermediate_size, Image.Resampling.LANCZOS)
            
            final_size = (intermediate_size[0] // 2, intermediate_size[1] // 2)
            canvas = canvas.resize(final_size, Image.Resampling.LANCZOS)
            
            ax = int(round((-bbox[0] + margin) / self.supersample_factor))
            ay = int(round((-bbox[1] + margin) / self.supersample_factor))
        elif self.supersample_factor &amp;gt; 1:
            new_size = (width // self.supersample_factor, height // self.supersample_factor)
            canvas = canvas.resize(new_size, Image.Resampling.LANCZOS)
            ax = int(round((-bbox[0] + margin) / self.supersample_factor))
            ay = int(round((-bbox[1] + margin) / self.supersample_factor))
        else:
            ax = -bbox[0] + margin
            ay = -bbox[1] + margin

        return canvas, (ax, ay)

    # -----------------------------
    # Layout &amp;amp; order
    # -----------------------------
    def _prepare_letter_sprites(self):
        &amp;quot;&amp;quot;&amp;quot;Pre-render letter sprites and compute front-face layout.&amp;quot;&amp;quot;&amp;quot;
        font_px = int(self.font_size * self.initial_scale)
        font = self._get_font(font_px)

        tmp = Image.new(&amp;quot;RGBA&amp;quot;, (4, 4), (0, 0, 0, 0))
        d = ImageDraw.Draw(tmp)
        full_bbox = d.textbbox((0, 0), self.text, font=font)
        text_width = full_bbox[2] - full_bbox[0]
        text_height = full_bbox[3] - full_bbox[1]

        cx, cy = self.initial_position
        start_x = cx - text_width // 2
        start_y = cy - text_height // 2

        current_x = start_x
        visible_positions: List[Tuple[int, int]] = []

        self.letter_sprites = []
        for letter in self.text:
            if letter == &amp;apos; &amp;apos;:
                space_width = font_px // 3
                sprite = LetterSprite(
                    char=letter,
                    sprite_3d=None,
                    position=(current_x, start_y),
                    width=space_width,
                    height=0,
                    anchor=(0, 0)
                )
                self.letter_sprites.append(sprite)
                visible_positions.append((current_x, start_y))
                current_x += space_width
            else:
                letter_bbox = d.textbbox((0, 0), letter, font=font)
                advance = letter_bbox[2] - letter_bbox[0]

                sprite_3d, (ax, ay) = self._render_3d_letter(letter, self.initial_scale, 1.0, 1.0)
                paste_x = current_x - ax
                paste_y = start_y - ay

                sprite = LetterSprite(
                    char=letter,
                    sprite_3d=sprite_3d,
                    position=(paste_x, paste_y),
                    width=sprite_3d.width if sprite_3d else 0,
                    height=sprite_3d.height if sprite_3d else 0,
                    anchor=(ax, ay)
                )
                self.letter_sprites.append(sprite)
                visible_positions.append((current_x, start_y))
                current_x += advance

        self._log_pos(
            f&amp;quot;Dissolve layout -&amp;gt; center={self.initial_position}, front_text_bbox=({text_width},{text_height}), &amp;quot;
            f&amp;quot;start_topleft=({start_x},{start_y})&amp;quot;
        )
        self._log_pos(f&amp;quot;Letter positions frozen at: {visible_positions}&amp;quot;)

    def _init_dissolve_order(self):
        if self.randomize_order:
            indices = [i for i, ch in enumerate(self.text) if ch != &amp;apos; &amp;apos;]
            random.shuffle(indices)
            self.dissolve_order = indices
        else:
            self.dissolve_order = [i for i, ch in enumerate(self.text) if ch != &amp;apos; &amp;apos;]
        self._log_pos(f&amp;quot;Dissolve order (excluding spaces): {self.dissolve_order}&amp;quot;)

    # -----------------------------
    # Frame-accurate schedule
    # -----------------------------
    def _build_frame_timeline(self):
        &amp;quot;&amp;quot;&amp;quot;Compute per-letter schedule in integer frames and log it.&amp;quot;&amp;quot;&amp;quot;
        min_fade_frames = max(2, int(round(self.post_fade_seconds * self.fps)))
        dissolve_frames = max(1, int(round(self.dissolve_duration * self.fps)))
        self._timeline.clear()
        self._entered_dissolve_logged.clear()
        self._hold_logged.clear()

        # 1) initial pass
        for order_idx, letter_idx in enumerate(self.dissolve_order):
            start_seconds = self.stable_duration + order_idx * self.dissolve_stagger
            start_frame = int(round(start_seconds * self.fps))
            hold_end = start_frame + max(0, self.pre_dissolve_hold_frames - 1)
            end_frame = hold_end + dissolve_frames  # dissolve begins AFTER hold
            fade_end = end_frame + min_fade_frames

            # clamp into clip range
            start_frame = max(0, min(self.total_frames - 1, start_frame))
            hold_end = max(start_frame, min(self.total_frames - 1, hold_end))
            end_frame = max(hold_end, min(self.total_frames - 1, end_frame))
            fade_end = max(end_frame, min(self.total_frames - 1, fade_end))

            self._timeline[letter_idx] = _LetterTiming(
                start=start_frame,
                hold_end=hold_end,
                end=end_frame,
                fade_end=fade_end,
                order_index=order_idx
            )

        # 2) Optional pass to prevent gaps: ensure prev.fade_end &amp;gt;= next.start
        if self.ensure_no_gap and len(self.dissolve_order) &amp;gt; 1:
            for i in range(len(self.dissolve_order) - 1):
                a = self._timeline[self.dissolve_order[i]]
                b = self._timeline[self.dissolve_order[i + 1]]
                if a.fade_end &amp;lt; b.start:
                    # extend a.fade_end up to b.start
                    new_fade_end = b.start
                    self._timeline[self.dissolve_order[i]] = _LetterTiming(
                        start=a.start, hold_end=a.hold_end, end=a.end,
                        fade_end=new_fade_end, order_index=a.order_index
                    )
                    self._log_jump(
                        f&amp;quot;Extended fade: letter#{i} fade_end {a.fade_end} -&amp;gt; {new_fade_end} to meet next.start {b.start}&amp;quot;
                    )

        # 3) Log schedule
        lines = []
        for i, idx in enumerate(self.dissolve_order):
            t = self._timeline[idx]
            ch = self.letter_sprites[idx].char if 0 &amp;lt;= idx &amp;lt; len(self.letter_sprites) else &amp;apos;?&amp;apos;
            lines.append(
                f&amp;quot;[JUMP_CUT] schedule[{i}] &amp;apos;{ch}&amp;apos; idx={idx}: start={t.start}, hold_end={t.hold_end}, &amp;quot;
                f&amp;quot;end={t.end}, fade_end={t.fade_end}&amp;quot;
            )
        if self.debug:
            print(&amp;quot;\n&amp;quot;.join(lines))

    def debug_print_schedule(self):
        &amp;quot;&amp;quot;&amp;quot;Public helper for tests.&amp;quot;&amp;quot;&amp;quot;
        self._build_frame_timeline()

    # -----------------------------
    # External handoff
    # -----------------------------
    def set_initial_state(self, scale: float, position: Tuple[int, int], alpha: float = None,
                          is_behind: bool = None, segment_mask: np.ndarray = None):
        self.initial_scale = scale
        self.initial_position = position
        if alpha is not None:
            self.stable_alpha = max(0.0, min(1.0, alpha))
        if is_behind is not None:
            self.is_behind = is_behind
        if segment_mask is not None:
            self.segment_mask = segment_mask
        self.letter_sprites = []
        self._log_pos(f&amp;quot;Received handoff -&amp;gt; center={position}, scale={scale:.3f}, &amp;quot;
                      f&amp;quot;alpha={self.stable_alpha:.3f}, is_behind={self.is_behind}&amp;quot;)
        self._prepare_letter_sprites()
        self._build_frame_timeline()

    # -----------------------------
    # Kill mask helper
    # -----------------------------
    def _add_dissolve_holes(self, letter_idx: int, progress_0_1: float):
        sprite = self.letter_sprites[letter_idx]
        if sprite.sprite_3d is None:
            return
        if letter_idx not in self.letter_kill_masks:
            self.letter_kill_masks[letter_idx] = np.zeros(
                (sprite.sprite_3d.height, sprite.sprite_3d.width), dtype=np.uint8
            )
        num_holes = int(progress_0_1 * 20)
        for _ in range(num_holes):
            x = np.random.randint(0, sprite.sprite_3d.width)
            y = np.random.randint(0, sprite.sprite_3d.height)
            radius = np.random.randint(2, 8)
            cv2.circle(self.letter_kill_masks[letter_idx], (x, y), radius, 1, -1)

    # -----------------------------
    # Frame generation
    # -----------------------------
    def generate_frame(self, frame_number: int, background: np.ndarray) -&amp;gt; np.ndarray:
        frame = background.copy()
        if frame.shape[2] == 3:
            frame = cv2.cvtColor(frame, cv2.COLOR_RGB2RGBA)

        # Optional dynamic mask when behind subject
        current_mask = None
        if self.is_behind and self.segment_mask is not None:
            if frame_number not in self._frame_mask_cache:
                try:
                    from utils.segmentation.segment_extractor import extract_foreground_mask
                    current_rgb = background[:, :, :3] if background.shape[2] == 4 else background
                    current_mask = extract_foreground_mask(current_rgb)
                    if current_mask.shape[:2] != (self.resolution[1], self.resolution[0]):
                        current_mask = cv2.resize(current_mask, self.resolution, interpolation=cv2.INTER_LINEAR)
                    current_mask = cv2.GaussianBlur(current_mask, (3, 3), 0)
                    kernel = np.ones((3, 3), np.uint8)
                    current_mask = cv2.dilate(current_mask, kernel, iterations=1)
                    current_mask = (current_mask &amp;gt; 128).astype(np.uint8) * 255
                    self._frame_mask_cache[frame_number] = current_mask
                    if self.debug and frame_number % 10 == 0:
                        self._log_pos(f&amp;quot;Dynamic mask extracted for frame {frame_number}&amp;quot;)
                except Exception as e:
                    current_mask = self.segment_mask
                    if self.debug:
                        self._log_pos(f&amp;quot;Using static mask for frame {frame_number}: {e}&amp;quot;)
            else:
                current_mask = self._frame_mask_cache[frame_number]

        canvas = Image.fromarray(frame)

        # Helpful first-frame log
        if self.debug and frame_number == 0 and self.letter_sprites:
            s0 = self.letter_sprites[self.dissolve_order[0]]
            self._log_pos(
                f&amp;quot;Frame0 check -&amp;gt; first letter &amp;apos;{s0.char}&amp;apos; paste_topleft={s0.position}, anchor={s0.anchor}&amp;quot;
            )

        # Process letters
        for idx in self.dissolve_order:
            sprite = self.letter_sprites[idx]
            if sprite.sprite_3d is None:
                continue

            timing = self._timeline[idx]
            f = frame_number

            # Determine phase by frame number (frame-accurate)
            if f &amp;lt; timing.start:
                phase = &amp;quot;stable&amp;quot;
                alpha_mult = self.stable_alpha
                scale = 1.0
                float_y = 0
                add_holes = False
            elif timing.start &amp;lt;= f &amp;lt;= timing.hold_end:
                # 1-frame (or more) safety hold at EXACT stable_alpha
                if not self._hold_logged.get(idx):
                    self._log_jump(
                        f&amp;quot;&amp;apos;{sprite.char}&amp;apos; enters HOLD at frame {f} (alpha={self.stable_alpha:.3f})&amp;quot;
                    )
                    self._hold_logged[idx] = True
                phase = &amp;quot;hold&amp;quot;
                alpha_mult = self.stable_alpha
                scale = 1.0
                float_y = 0
                add_holes = False
            elif timing.hold_end &amp;lt; f &amp;lt;= timing.end:
                # Dissolve begins AFTER hold; progress starts at ~0 on first dissolve frame
                denom = max(1, (timing.end - timing.hold_end))
                letter_t = (f - timing.hold_end) / denom
                smooth_t = self._smoothstep(letter_t)
                if not self._entered_dissolve_logged.get(idx):
                    self._log_jump(
                        f&amp;quot;&amp;apos;{sprite.char}&amp;apos; begins DISSOLVE at frame {f} &amp;quot;
                        f&amp;quot;(t={letter_t:.3f}, alpha≈{self.stable_alpha * (1.0 - 0.98 * 0):.3f})&amp;quot;
                    )
                    self._entered_dissolve_logged[idx] = True
                phase = &amp;quot;dissolve&amp;quot;
                alpha_mult = self.stable_alpha * (1.0 - smooth_t * 0.98)  # approaches ~0.02*stable_alpha
                scale = 1.0 + smooth_t * (self.max_dissolve_scale - 1.0)
                float_y = -smooth_t * self.float_distance
                add_holes = letter_t &amp;gt; 0.3
                if add_holes:
                    self._add_dissolve_holes(idx, letter_t)
            elif timing.end &amp;lt; f &amp;lt;= timing.fade_end:
                # Fade tail (guaranteed &amp;gt;= 2 frames)
                fade_denom = max(1, (timing.fade_end - timing.end))
                fade_t = (f - timing.end) / fade_denom
                phase = &amp;quot;fade&amp;quot;
                alpha_mult = self.stable_alpha * 0.02 * (1.0 - fade_t)
                scale = self.max_dissolve_scale
                float_y = -self.float_distance
                add_holes = True
                if idx not in self.letter_kill_masks:
                    # ensure it&amp;apos;s &amp;quot;holey&amp;quot; in fade
                    self.letter_kill_masks[idx] = np.ones(
                        (sprite.sprite_3d.height, sprite.sprite_3d.width), dtype=np.uint8
                    )
            else:
                # Completely gone
                continue

            # Copy and transform sprite
            sprite_img = sprite.sprite_3d.copy()
            pos_x, pos_y = sprite.position

            if scale != 1.0:
                new_w = int(round(sprite_img.width * scale))
                new_h = int(round(sprite_img.height * scale))
                sprite_img = sprite_img.resize((new_w, new_h), Image.Resampling.LANCZOS)
                pos_x -= (new_w - sprite.sprite_3d.width) // 2
                pos_y -= (new_h - sprite.sprite_3d.height) // 2

            pos_y += int(round(float_y))
            sprite_array = np.array(sprite_img)

            # Apply kill mask if any (scaled to current sprite size)
            if idx in self.letter_kill_masks and np.any(self.letter_kill_masks[idx]):
                kill_mask = self.letter_kill_masks[idx]
                if (sprite_img.width, sprite_img.height) != (kill_mask.shape[1], kill_mask.shape[0]):
                    kill_mask = cv2.resize(kill_mask, (sprite_img.width, sprite_img.height),
                                           interpolation=cv2.INTER_NEAREST)
                sprite_array[:, :, 3] = (sprite_array[:, :, 3] * (1 - kill_mask)).astype(np.uint8)

            # Overall alpha
            sprite_array[:, :, 3] = (sprite_array[:, :, 3] * alpha_mult).astype(np.uint8)
            sprite_img = Image.fromarray(sprite_array)

            # Occlusion if behind subject
            if self.is_behind and current_mask is not None:
                sprite_np = np.array(sprite_img)
                sp_h, sp_w = sprite_np.shape[:2]
                y1 = max(0, int(pos_y)); y2 = min(self.resolution[1], int(pos_y) + sp_h)
                x1 = max(0, int(pos_x)); x2 = min(self.resolution[0], int(pos_x) + sp_w)
                sy1 = max(0, -int(pos_y)); sy2 = sy1 + (y2 - y1)
                sx1 = max(0, -int(pos_x)); sx2 = sx1 + (x2 - x1)

                if y2 &amp;gt; y1 and x2 &amp;gt; x1:
                    mask_region = current_mask[y1:y2, x1:x2]
                    sprite_alpha = sprite_np[sy1:sy2, sx1:sx2, 3].astype(np.float32)
                    mask_factor = mask_region.astype(np.float32) / 255.0
                    sprite_alpha *= (1.0 - mask_factor)
                    sprite_np[sy1:sy2, sx1:sx2, 3] = sprite_alpha.astype(np.uint8)
                    sprite_img = Image.fromarray(sprite_np)

            canvas.paste(sprite_img, (int(pos_x), int(pos_y)), sprite_img)

        result = np.array(canvas)
        return result[:, :, :3] if result.shape[2] == 4 else result</file>
    <file path="apply_3d_text_animation.py">#!/usr/bin/env python3
&amp;quot;&amp;quot;&amp;quot;
Apply 3D text motion and dissolve animation to any video file.

Usage:
    python apply_3d_text_animation.py &amp;lt;video_path&amp;gt; [options]
    
Examples:
    # Basic usage with default text
    python apply_3d_text_animation.py my_video.mp4
    
    # Custom text
    python apply_3d_text_animation.py my_video.mp4 --text &amp;quot;AWESOME VIDEO&amp;quot;
    
    # Custom timing and position
    python apply_3d_text_animation.py my_video.mp4 --text &amp;quot;HELLO&amp;quot; --position center --motion-duration 1.0
    
    # Loop animation throughout video
    python apply_3d_text_animation.py my_video.mp4 --loop --text &amp;quot;SUBSCRIBE&amp;quot;
&amp;quot;&amp;quot;&amp;quot;

import cv2
import numpy as np
import subprocess
import argparse
import os
from pathlib import Path
from utils.animations.text_3d_motion import Text3DMotion
from utils.animations.letter_3d_dissolve import Letter3DDissolve


def parse_position(position_str, width, height):
    &amp;quot;&amp;quot;&amp;quot;Parse position string to coordinates.&amp;quot;&amp;quot;&amp;quot;
    positions = {
        &amp;apos;center&amp;apos;: (width // 2, height // 2),
        &amp;apos;top&amp;apos;: (width // 2, height // 4),
        &amp;apos;bottom&amp;apos;: (width // 2, 3 * height // 4),
        &amp;apos;left&amp;apos;: (width // 4, height // 2),
        &amp;apos;right&amp;apos;: (3 * width // 4, height // 2),
        &amp;apos;top-left&amp;apos;: (width // 4, height // 4),
        &amp;apos;top-right&amp;apos;: (3 * width // 4, height // 4),
        &amp;apos;bottom-left&amp;apos;: (width // 4, 3 * height // 4),
        &amp;apos;bottom-right&amp;apos;: (3 * width // 4, 3 * height // 4),
    }
    
    if position_str in positions:
        return positions[position_str]
    
    # Try to parse as &amp;quot;x,y&amp;quot; coordinates
    try:
        x, y = map(int, position_str.split(&amp;apos;,&amp;apos;))
        return (x, y)
    except:
        print(f&amp;quot;[JUMP_CUT] Warning: Invalid position &amp;apos;{position_str}&amp;apos;, using center&amp;quot;)
        return positions[&amp;apos;center&amp;apos;]


def extract_foreground_mask_safe(frame):
    &amp;quot;&amp;quot;&amp;quot;Safely extract foreground mask, return None if fails.&amp;quot;&amp;quot;&amp;quot;
    try:
        from utils.segmentation.segment_extractor import extract_foreground_mask
        mask = extract_foreground_mask(frame)
        print(f&amp;quot;[JUMP_CUT] Foreground mask extracted: {mask.shape}&amp;quot;)
        return mask
    except Exception as e:
        print(f&amp;quot;[JUMP_CUT] No foreground mask (text won&amp;apos;t go behind objects): {e}&amp;quot;)
        return None


def apply_animation_to_video(
    video_path,
    text=&amp;quot;HELLO WORLD&amp;quot;,
    output_path=None,
    motion_duration=0.75,
    dissolve_duration=1.5,
    position=&amp;apos;center&amp;apos;,
    final_opacity=0.5,
    font_size=140,
    text_color=(255, 220, 0),
    start_scale=2.0,
    end_scale=1.0,
    final_scale=0.9,
    loop=False,
    extract_mask=True,
    supersample=10,
    debug=False
):
    &amp;quot;&amp;quot;&amp;quot;
    Apply 3D text animation to a video file.
    
    Args:
        video_path: Path to input video
        text: Text to animate
        output_path: Output video path (auto-generated if None)
        motion_duration: Duration of motion phase in seconds
        dissolve_duration: Duration of dissolve phase in seconds
        position: Position of text (&amp;apos;center&amp;apos;, &amp;apos;top&amp;apos;, &amp;apos;bottom&amp;apos;, or &amp;apos;x,y&amp;apos;)
        final_opacity: Final opacity of text (0.0-1.0)
        font_size: Size of font
        text_color: RGB color tuple
        start_scale: Initial scale of text
        end_scale: Scale at end of motion
        final_scale: Final scale during dissolve
        loop: Whether to loop animation throughout video
        extract_mask: Whether to extract foreground mask for occlusion
        supersample: Supersampling factor for text rendering quality (higher = better quality, default: 4)
        debug: Enable debug logging
    
    Returns:
        Path to output video
    &amp;quot;&amp;quot;&amp;quot;
    
    # Open video
    cap = cv2.VideoCapture(video_path)
    if not cap.isOpened():
        raise ValueError(f&amp;quot;Could not open video: {video_path}&amp;quot;)
    
    # Get video properties
    fps = int(round(cap.get(cv2.CAP_PROP_FPS))) or 30
    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    video_duration = total_frames / fps
    
    print(f&amp;quot;[JUMP_CUT] Input video: {video_path}&amp;quot;)
    print(f&amp;quot;[JUMP_CUT] Resolution: {width}x{height}, FPS: {fps}&amp;quot;)
    print(f&amp;quot;[JUMP_CUT] Duration: {video_duration:.2f}s ({total_frames} frames)&amp;quot;)
    print(f&amp;quot;[JUMP_CUT] Text: &amp;apos;{text}&amp;apos;&amp;quot;)
    
    # Parse position
    text_position = parse_position(position, width, height)
    print(f&amp;quot;[JUMP_CUT] Text position: {text_position}&amp;quot;)
    
    # Calculate animation frames
    motion_frames = int(round(motion_duration * fps))
    dissolve_frames = int(round(dissolve_duration * fps))
    animation_frames = motion_frames + dissolve_frames
    animation_duration = animation_frames / fps
    
    print(f&amp;quot;[JUMP_CUT] Animation: {animation_duration:.2f}s ({animation_frames} frames)&amp;quot;)
    print(f&amp;quot;[JUMP_CUT]   Motion: {motion_duration:.2f}s ({motion_frames} frames)&amp;quot;)
    print(f&amp;quot;[JUMP_CUT]   Dissolve: {dissolve_duration:.2f}s ({dissolve_frames} frames)&amp;quot;)
    
    # Extract foreground mask from first frame (optional)
    segment_mask = None
    if extract_mask:
        cap.set(cv2.CAP_PROP_POS_FRAMES, 0)
        ret, first_frame = cap.read()
        if ret:
            first_frame_rgb = cv2.cvtColor(first_frame, cv2.COLOR_BGR2RGB)
            segment_mask = extract_foreground_mask_safe(first_frame_rgb)
        cap.set(cv2.CAP_PROP_POS_FRAMES, 0)  # Reset to beginning
    
    # Create animations
    motion = Text3DMotion(
        duration=motion_duration,
        fps=fps,
        resolution=(width, height),
        text=text,
        segment_mask=segment_mask,
        font_size=font_size,
        text_color=text_color,
        depth_color=tuple(int(c * 0.8) for c in text_color),  # Slightly darker depth
        depth_layers=8,
        depth_offset=3,
        start_scale=start_scale,
        end_scale=end_scale,
        final_scale=final_scale,
        start_position=text_position,
        end_position=text_position,
        shrink_duration=motion_duration * 0.8,
        settle_duration=motion_duration * 0.2,
        final_alpha=final_opacity,
        shadow_offset=6,
        outline_width=2,
        perspective_angle=0,
        supersample_factor=supersample,
        glow_effect=True,
        debug=debug,
    )
    
    dissolve = Letter3DDissolve(
        duration=dissolve_duration,
        fps=fps,
        resolution=(width, height),
        text=text,
        font_size=font_size,
        text_color=text_color,
        depth_color=tuple(int(c * 0.8) for c in text_color),
        depth_layers=8,
        depth_offset=3,
        initial_scale=final_scale,
        initial_position=text_position,
        stable_duration=0.1,
        stable_alpha=final_opacity,
        dissolve_duration=0.5,
        dissolve_stagger=0.1,
        float_distance=40,
        max_dissolve_scale=1.3,
        randomize_order=False,
        segment_mask=segment_mask,
        is_behind=False,  # Will be set by handoff
        shadow_offset=6,
        outline_width=2,
        supersample_factor=supersample,
        post_fade_seconds=0.10,
        pre_dissolve_hold_frames=1,
        ensure_no_gap=True,
        debug=debug,
    )
    
    # Generate output path if not provided
    if output_path is None:
        input_path = Path(video_path)
        output_path = input_path.parent / f&amp;quot;{input_path.stem}_3d_text.mp4&amp;quot;
    
    # Create video writer
    fourcc = cv2.VideoWriter_fourcc(*&amp;apos;mp4v&amp;apos;)
    out = cv2.VideoWriter(str(output_path), fourcc, fps, (width, height))
    
    print(f&amp;quot;[JUMP_CUT] Processing video...&amp;quot;)
    
    frame_count = 0
    animation_cycle = 0
    
    while True:
        ret, frame = cap.read()
        if not ret:
            break
        
        # Convert BGR to RGB for processing
        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        
        # Calculate animation frame index
        if loop:
            # Loop animation throughout video
            anim_frame = frame_count % animation_frames
            if anim_frame == 0 and frame_count &amp;gt; 0:
                animation_cycle += 1
                print(f&amp;quot;[JUMP_CUT] Starting animation cycle {animation_cycle + 1}&amp;quot;)
        else:
            # Single animation at start
            anim_frame = frame_count if frame_count &amp;lt; animation_frames else -1
        
        # Apply animation if within animation range
        if anim_frame &amp;gt;= 0:
            if anim_frame &amp;lt; motion_frames:
                # Motion phase
                frame_rgb = motion.generate_frame(anim_frame, frame_rgb)
                
                # Handle handoff on last motion frame
                if anim_frame == motion_frames - 1:
                    final_state = motion.get_final_state()
                    if final_state and (frame_count &amp;lt; motion_frames or loop):
                        # Only do handoff once per cycle
                        if debug:
                            print(f&amp;quot;[JUMP_CUT] Handoff at frame {frame_count}: &amp;quot;
                                  f&amp;quot;center={final_state.center_position}, &amp;quot;
                                  f&amp;quot;scale={final_state.scale:.3f}&amp;quot;)
                        dissolve.set_initial_state(
                            scale=final_state.scale,
                            position=final_state.center_position,
                            alpha=final_opacity,
                            is_behind=final_state.is_behind,
                            segment_mask=segment_mask
                        )
            else:
                # Dissolve phase
                dissolve_frame = anim_frame - motion_frames
                frame_rgb = dissolve.generate_frame(dissolve_frame, frame_rgb)
        
        # Convert back to BGR and write
        frame_bgr = cv2.cvtColor(frame_rgb, cv2.COLOR_RGB2BGR)
        out.write(frame_bgr)
        
        frame_count += 1
        if frame_count % (fps * 5) == 0:  # Progress every 5 seconds
            progress = (frame_count / total_frames) * 100
            print(f&amp;quot;[JUMP_CUT] Progress: {progress:.1f}% ({frame_count}/{total_frames} frames)&amp;quot;)
    
    # Clean up
    cap.release()
    out.release()
    
    print(f&amp;quot;[JUMP_CUT] Video saved to: {output_path}&amp;quot;)
    
    # Convert to H.264 for compatibility
    h264_path = Path(output_path).parent / f&amp;quot;{Path(output_path).stem}_h264.mp4&amp;quot;
    print(f&amp;quot;[JUMP_CUT] Converting to H.264...&amp;quot;)
    
    subprocess.run([
        &amp;apos;ffmpeg&amp;apos;, &amp;apos;-i&amp;apos;, str(output_path),
        &amp;apos;-c:v&amp;apos;, &amp;apos;libx264&amp;apos;, &amp;apos;-preset&amp;apos;, &amp;apos;fast&amp;apos;, &amp;apos;-crf&amp;apos;, &amp;apos;23&amp;apos;,
        &amp;apos;-pix_fmt&amp;apos;, &amp;apos;yuv420p&amp;apos;, &amp;apos;-movflags&amp;apos;, &amp;apos;+faststart&amp;apos;,
        str(h264_path), &amp;apos;-y&amp;apos;
    ], check=True, capture_output=True)
    
    # Remove intermediate file
    os.remove(output_path)
    
    print(f&amp;quot;[JUMP_CUT] ✅ Final video: {h264_path}&amp;quot;)
    return str(h264_path)


def main():
    parser = argparse.ArgumentParser(
        description=&amp;quot;Apply 3D text animation to any video&amp;quot;,
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog=&amp;quot;&amp;quot;&amp;quot;
Examples:
  %(prog)s video.mp4
  %(prog)s video.mp4 --text &amp;quot;AWESOME&amp;quot;
  %(prog)s video.mp4 --text &amp;quot;SUBSCRIBE&amp;quot; --position bottom --loop
  %(prog)s video.mp4 --text &amp;quot;2024&amp;quot; --color 255,0,0 --size 200
  %(prog)s video.mp4 --position 100,200 --motion-duration 2.0
        &amp;quot;&amp;quot;&amp;quot;
    )
    
    parser.add_argument(&amp;apos;video&amp;apos;, help=&amp;apos;Input video file path&amp;apos;)
    parser.add_argument(&amp;apos;--text&amp;apos;, default=&amp;apos;HELLO WORLD&amp;apos;, help=&amp;apos;Text to animate (default: HELLO WORLD)&amp;apos;)
    parser.add_argument(&amp;apos;--output&amp;apos;, &amp;apos;-o&amp;apos;, help=&amp;apos;Output video path (auto-generated if not specified)&amp;apos;)
    
    # Timing
    parser.add_argument(&amp;apos;--motion-duration&amp;apos;, type=float, default=0.75,
                        help=&amp;apos;Duration of motion phase in seconds (default: 0.75)&amp;apos;)
    parser.add_argument(&amp;apos;--dissolve-duration&amp;apos;, type=float, default=1.5,
                        help=&amp;apos;Duration of dissolve phase in seconds (default: 1.5)&amp;apos;)
    parser.add_argument(&amp;apos;--loop&amp;apos;, action=&amp;apos;store_true&amp;apos;,
                        help=&amp;apos;Loop animation throughout video&amp;apos;)
    
    # Position
    parser.add_argument(&amp;apos;--position&amp;apos;, &amp;apos;-p&amp;apos;, default=&amp;apos;center&amp;apos;,
                        help=&amp;apos;Text position: center, top, bottom, left, right, or x,y (default: center)&amp;apos;)
    
    # Appearance
    parser.add_argument(&amp;apos;--size&amp;apos;, type=int, default=140,
                        help=&amp;apos;Font size (default: 140)&amp;apos;)
    parser.add_argument(&amp;apos;--color&amp;apos;, default=&amp;apos;255,220,0&amp;apos;,
                        help=&amp;apos;Text color as R,G,B (default: 255,220,0 - golden yellow)&amp;apos;)
    parser.add_argument(&amp;apos;--opacity&amp;apos;, type=float, default=0.5,
                        help=&amp;apos;Final text opacity 0.0-1.0 (default: 0.5)&amp;apos;)
    parser.add_argument(&amp;apos;--start-scale&amp;apos;, type=float, default=2.0,
                        help=&amp;apos;Initial scale of text (default: 2.0)&amp;apos;)
    parser.add_argument(&amp;apos;--end-scale&amp;apos;, type=float, default=1.0,
                        help=&amp;apos;Scale at end of motion (default: 1.0)&amp;apos;)
    parser.add_argument(&amp;apos;--final-scale&amp;apos;, type=float, default=0.9,
                        help=&amp;apos;Final scale during dissolve (default: 0.9)&amp;apos;)
    
    # Options
    parser.add_argument(&amp;apos;--no-mask&amp;apos;, action=&amp;apos;store_true&amp;apos;,
                        help=&amp;apos;Disable foreground mask extraction (text won\&amp;apos;t go behind objects)&amp;apos;)
    parser.add_argument(&amp;apos;--supersample&amp;apos;, type=int, default=10,
                        help=&amp;apos;Supersampling factor for text quality, higher=better (default: 10, was 2)&amp;apos;)
    parser.add_argument(&amp;apos;--debug&amp;apos;, action=&amp;apos;store_true&amp;apos;,
                        help=&amp;apos;Enable debug logging&amp;apos;)
    
    args = parser.parse_args()
    
    # Parse color
    try:
        color = tuple(map(int, args.color.split(&amp;apos;,&amp;apos;)))
        if len(color) != 3 or any(c &amp;lt; 0 or c &amp;gt; 255 for c in color):
            raise ValueError
    except:
        print(f&amp;quot;[JUMP_CUT] Warning: Invalid color &amp;apos;{args.color}&amp;apos;, using default&amp;quot;)
        color = (255, 220, 0)
    
    # Apply animation
    try:
        output = apply_animation_to_video(
            video_path=args.video,
            text=args.text,
            output_path=args.output,
            motion_duration=args.motion_duration,
            dissolve_duration=args.dissolve_duration,
            position=args.position,
            final_opacity=args.opacity,
            font_size=args.size,
            text_color=color,
            start_scale=args.start_scale,
            end_scale=args.end_scale,
            final_scale=args.final_scale,
            loop=args.loop,
            extract_mask=not args.no_mask,
            supersample=args.supersample,
            debug=args.debug
        )
        print(f&amp;quot;\n✅ Success! Output saved to: {output}&amp;quot;)
    except Exception as e:
        print(f&amp;quot;\n❌ Error: {e}&amp;quot;)
        return 1
    
    return 0


if __name__ == &amp;apos;__main__&amp;apos;:
    exit(main())</file>
  </files>
  <project_tree>./
├── ai-docs/
├── ai-services/
├── aws_config/
├── cartoon-head-detection/
├── cartoon-test/
├── config/
├── debug_artifacts/
├── docs/
├── hooks/
├── lambda/
├── lambda_function/
├── layer/
├── outputs/
├── pipeline/
├── sound_effects/
├── test_data/
├── tests/
├── uploads/
├── utils/
│   ├── animations/
│   │   ├── letter_3d_dissolve.py *
│   │   └── text_3d_motion.py *
│   ├── auto_comment/
│   ├── auto_snark/
│   ├── aws/
│   ├── bulk_animate_image/
│   ├── captions/
│   ├── contour_extraction/
│   ├── downsample/
│   ├── draw-euler/
│   ├── editing_tricks/
│   ├── end_to_end_drawing/
│   ├── image-cap/
│   ├── image_generation/
│   ├── sam2_api/
│   ├── scene_management/
│   ├── segmentation/
│   ├── sound_effects/
│   ├── text_placement/
│   ├── tracking/
│   ├── vectorize/
│   ├── video_effects/
│   ├── video_overlay/
│   ├── video_segmentation/
│   └── video_utils/
├── video-processing/
├── w_components/
├── w_dissolve_frames/
└── apply_3d_text_animation.py *</project_tree>
  <summary total_files="3" issue="the same issue occurs, the resolution of the letters in the final vidoe is low, there's a &quot;staircase&quot; effect in letters like A, see the image for example: [Image #1]"/>
  <debugging>When fixing this issue, add debug log prints to help diagnose if the fix doesn't work.
All debug prints must follow the structure: [TEXT_QUALITY] message
Example: [TEXT_QUALITY] Letter positions frozen at: [(350, 180), (375, 180), ...]
This will help track the fix progress and identify any remaining issues.</debugging>
</context>
